{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j-IXmTY6GTPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95fa15c-15ba-40b9-d9bc-12c9b82c10d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=88de671a76f4fd10d450062c632b03b4523ae9fed28dab6c38385b6d087b1926\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "Project packaged successfully: Complete_Data_Science_Project.zip\n"
          ]
        }
      ],
      "source": [
        "!pip install fpdf\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from fpdf import FPDF\n",
        "import pickle\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Create project folder structure\n",
        "project_name = \"Complete_Data_Science_Project\"\n",
        "subfolders = [\"data\", \"models\", \"notebooks\", \"reports\", \"visualizations\"]\n",
        "for folder in subfolders:\n",
        "    os.makedirs(f\"{project_name}/{folder}\", exist_ok=True)\n",
        "\n",
        "# 1. Generate synthetic data (simulating customer churn data)\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'CustomerID': np.arange(1, 101),\n",
        "    'Tenure': np.random.randint(1, 72, 100),\n",
        "    'MonthlyCharges': np.random.uniform(20, 120, 100),\n",
        "    'TotalCharges': np.random.uniform(100, 8000, 100),\n",
        "    'Churn': np.random.choice([0, 1], 100)\n",
        "})\n",
        "data.to_csv(f\"{project_name}/data/customer_data.csv\", index=False)\n",
        "\n",
        "# 2. Data Cleaning and Preprocessing\n",
        "data['TotalCharges'] = data['TotalCharges'].replace(' ', np.nan)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split data into features and target\n",
        "X = data[['Tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "y = data['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Model Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Save confusion matrix as an image\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(2)\n",
        "plt.xticks(tick_marks, ['No Churn', 'Churn'], rotation=45)\n",
        "plt.yticks(tick_marks, ['No Churn', 'Churn'])\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{project_name}/visualizations/confusion_matrix.png\")\n",
        "plt.close()\n",
        "\n",
        "# Generate ROC curve and AUC\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Save ROC curve as an image\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(f\"{project_name}/visualizations/roc_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "# 5. Create detailed PDF report\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", size=16)\n",
        "pdf.cell(200, 10, \"Complete Data Science Project: Customer Churn Analysis\", ln=True, align='C')\n",
        "pdf.set_font(\"Arial\", size=12)\n",
        "pdf.ln(10)\n",
        "pdf.multi_cell(0, 10, \"1. Introduction:\\nThis project aims to predict customer churn for a telecommunications company. \"\n",
        "    \"The analysis identifies the key factors that contribute to churn and provides recommendations for customer retention.\")\n",
        "pdf.ln(5)\n",
        "pdf.multi_cell(0, 10, \"2. Methodology:\\nThe dataset includes customer tenure, monthly charges, and total charges as features. \"\n",
        "    \"Data preprocessing, feature selection, and a Random Forest model were used for prediction.\")\n",
        "pdf.ln(5)\n",
        "pdf.multi_cell(0, 10, \"3. Analysis and Results:\\nThe model achieved an accuracy of {:.2f}. The confusion matrix and ROC curve are included below.\".format(model.score(X_test, y_test)))\n",
        "pdf.image(f\"{project_name}/visualizations/confusion_matrix.png\", x=10, y=None, w=100)\n",
        "pdf.image(f\"{project_name}/visualizations/roc_curve.png\", x=10, y=None, w=100)\n",
        "pdf.ln(5)\n",
        "pdf.multi_cell(0, 10, \"4. Conclusions and Recommendations:\\nThe analysis suggests focusing on customers with longer tenures and higher charges. \"\n",
        "    \"Improving customer service and offering tailored discounts may help retain customers.\")\n",
        "pdf.output(f\"{project_name}/reports/Customer_Churn_Analysis_Report.pdf\")\n",
        "\n",
        "# 6. Create README.md\n",
        "readme_content = f\"\"\"\n",
        "# Complete Data Science Project: Customer Churn Analysis\n",
        "\n",
        "## Project Description\n",
        "This project aims to predict customer churn for a telecommunications company, analyzing customer tenure, monthly charges, and total charges.\n",
        "\n",
        "## Objectives\n",
        "- Predict customer churn using machine learning models.\n",
        "- Provide insights into key factors contributing to churn.\n",
        "\n",
        "## How to Run the Code\n",
        "1. Ensure you have Python 3.x installed.\n",
        "2. Install dependencies using: `pip install -r requirements.txt`.\n",
        "3. Run the notebook or script to reproduce the results.\n",
        "\n",
        "## Results\n",
        "The Random Forest model achieved an accuracy of {model.score(X_test, y_test):.2f}. See the report for detailed analysis.\n",
        "\n",
        "## Requirements\n",
        "- Python 3.x\n",
        "- Libraries: pandas, numpy, matplotlib, sklearn, fpdf\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{project_name}/README.md\", \"w\") as file:\n",
        "    file.write(readme_content)\n",
        "\n",
        "# 7. Save trained model\n",
        "with open(f\"{project_name}/models/random_forest_model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "# 8. Create Jupyter Notebook\n",
        "notebook_content = \"\"\"\n",
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"# Complete Data Science Project: Customer Churn Analysis\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"import pandas as pd\",\n",
        "    \"import numpy as np\",\n",
        "    \"from sklearn.model_selection import train_test_split\",\n",
        "    \"from sklearn.ensemble import RandomForestClassifier\",\n",
        "    \"from sklearn.metrics import classification_report, confusion_matrix\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"## Data Loading and Preprocessing\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"data = pd.read_csv('data/customer_data.csv')\",\n",
        "    \"data.head()\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"name\": \"python\",\n",
        "   \"version\": \"3.8\"\n",
        "  }\n",
        " }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{project_name}/notebooks/Complete_DS_Project.ipynb\", \"w\") as file:\n",
        "    file.write(notebook_content)\n",
        "\n",
        "# 9. Create ZIP file of the complete project\n",
        "zip_path = f\"{project_name}.zip\"\n",
        "with ZipFile(zip_path, 'w') as zipf:\n",
        "    for folder, _, files in os.walk(project_name):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(folder, file))\n",
        "\n",
        "print(f\"Project packaged successfully: {zip_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory for the README file if it doesn't exist\n",
        "import os\n",
        "\n",
        "os.makedirs('project_5_customer_feedback_analysis', exist_ok=True)\n",
        "\n",
        "# Create a detailed README content\n",
        "readme_content = (\n",
        "    \"# Project 5: Customer Feedback Analysis for an Online Store\\n\\n\"\n",
        "    \"## Project Overview\\n\"\n",
        "    \"This project focuses on analyzing customer feedback for an e-commerce business. \"\n",
        "    \"The main goal is to understand customer sentiment, identify common complaints and suggestions, \"\n",
        "    \"and provide actionable insights to improve product quality and customer satisfaction.\\n\\n\"\n",
        "\n",
        "    \"## Objectives\\n\"\n",
        "    \"- Analyze customer feedback data to understand sentiment and trends.\\n\"\n",
        "    \"- Use natural language processing (NLP) to classify feedback as positive, negative, or neutral.\\n\"\n",
        "    \"- Identify common topics and key issues mentioned by customers.\\n\"\n",
        "    \"- Provide recommendations based on customer feedback insights.\\n\\n\"\n",
        "\n",
        "    \"## Dataset\\n\"\n",
        "    \"The dataset used in this project is simulated to represent customer feedback for an online store. \"\n",
        "    \"It includes features such as customer ratings, text-based comments, and feedback timestamps.\\n\\n\"\n",
        "\n",
        "    \"## Methods\\n\"\n",
        "    \"- **Data Preprocessing:** Cleaning and preparing feedback data for analysis, including handling missing values and text normalization.\\n\"\n",
        "    \"- **Sentiment Analysis:** Using NLP techniques to classify feedback as positive, negative, or neutral.\\n\"\n",
        "    \"- **Topic Modeling:** Identifying common topics in customer feedback using techniques like Latent Dirichlet Allocation (LDA).\\n\"\n",
        "    \"- **Visualization:** Generating visual representations of sentiment distribution and key topics discussed by customers.\\n\\n\"\n",
        "\n",
        "    \"## Results\\n\"\n",
        "    \"The analysis revealed several key insights about customer sentiment and feedback:\\n\"\n",
        "    \"- **Positive Feedback:** Customers frequently praised product quality and customer service responsiveness.\\n\"\n",
        "    \"- **Negative Feedback:** Common complaints included delivery delays, product defects, and customer service issues.\\n\"\n",
        "    \"- **Suggestions:** Customers suggested improvements in delivery speed and product packaging.\\n\\n\"\n",
        "\n",
        "    \"## Key Insights\\n\"\n",
        "    \"- Positive sentiment is mainly driven by product quality and quick response from customer service.\\n\"\n",
        "    \"- Negative sentiment is primarily related to logistical issues, such as delivery delays.\\n\"\n",
        "    \"- Topic modeling helped identify areas for improvement, including better packaging and faster shipping.\\n\\n\"\n",
        "\n",
        "    \"## Visualizations\\n\"\n",
        "    \"The project includes several visualizations to help understand customer sentiment and feedback trends:\\n\"\n",
        "    \"- **Word Cloud:** Highlights common words in customer feedback.\\n\"\n",
        "    \"- **Sentiment Distribution:** Shows the proportion of positive, negative, and neutral feedback.\\n\"\n",
        "    \"- **Topic Distribution:** Displays the most frequent topics mentioned in feedback.\\n\\n\"\n",
        "\n",
        "    \"## How to Run the Project\\n\"\n",
        "    \"1. Clone the repository:\\n\"\n",
        "    \"   ```bash\\n\"\n",
        "    \"   git clone https://github.com/yourusername/project_5_customer_feedback_analysis.git\\n\"\n",
        "    \"   ```\\n\"\n",
        "    \"2. Navigate to the project directory:\\n\"\n",
        "    \"   ```bash\\n\"\n",
        "    \"   cd project_5_customer_feedback_analysis\\n\"\n",
        "    \"   ```\\n\"\n",
        "    \"3. Install the required libraries:\\n\"\n",
        "    \"   ```bash\\n\"\n",
        "    \"   pip install -r requirements.txt\\n\"\n",
        "    \"   ```\\n\"\n",
        "    \"4. Run the Jupyter Notebook or Python script:\\n\"\n",
        "    \"   ```bash\\n\"\n",
        "    \"   jupyter notebook customer_feedback_analysis.ipynb\\n\"\n",
        "    \"   # or\\n\"\n",
        "    \"   python feedback_analysis.py\\n\"\n",
        "    \"   ```\\n\\n\"\n",
        "\n",
        "    \"## Project Structure\\n\"\n",
        "    \"- **data/**: Contains the dataset used for feedback analysis.\\n\"\n",
        "    \"- **models/**: Stores trained models for sentiment analysis and topic modeling.\\n\"\n",
        "    \"- **reports/**: Includes the PDF report and visualizations generated during the analysis.\\n\"\n",
        "    \"- **scripts/**: Python scripts for data analysis, NLP, and visualization.\\n\"\n",
        "    \"- **README.md**: Detailed project description and execution guide.\\n\\n\"\n",
        "\n",
        "    \"## Requirements\\n\"\n",
        "    \"The project requires the following Python libraries:\\n\"\n",
        "    \"- pandas\\n\"\n",
        "    \"- numpy\\n\"\n",
        "    \"- scikit-learn\\n\"\n",
        "    \"- matplotlib\\n\"\n",
        "    \"- seaborn\\n\"\n",
        "    \"- nltk\\n\"\n",
        "    \"- fpdf\\n\"\n",
        "    \"Install them using:\\n\"\n",
        "    \"```bash\\n\"\n",
        "    \"pip install pandas numpy scikit-learn matplotlib seaborn nltk fpdf\\n\"\n",
        "    \"```\\n\\n\"\n",
        "\n",
        "    \"## Conclusion\\n\"\n",
        "    \"This project successfully demonstrates how to analyze and interpret customer feedback in an e-commerce setting. \"\n",
        "    \"The insights gained from this analysis can help businesses improve their products, services, and customer experience. \"\n",
        "    \"By addressing common issues and acting on customer suggestions, the company can increase satisfaction and customer loyalty.\\n\\n\"\n",
        "\n",
        "    \"## Future Improvements\\n\"\n",
        "    \"- Include more feedback features, such as customer demographics, to better understand sentiment differences among groups.\\n\"\n",
        "    \"- Experiment with advanced NLP models (e.g., BERT or GPT) for more accurate sentiment analysis and topic detection.\\n\"\n",
        "    \"- Develop a real-time dashboard for visualizing customer feedback trends and sentiment.\\n\\n\"\n",
        ")\n",
        "\n",
        "# Write the README.md file\n",
        "with open('project_5_customer_feedback_analysis/README.md', 'w') as file:\n",
        "    file.write(readme_content)\n",
        "\n",
        "print(\"README.md file has been created successfully!\")\n"
      ],
      "metadata": {
        "id": "kZGDb8TLelr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6dbbb7-96eb-44e2-8f2d-ace7c68c9745"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md file has been created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install fpdf pandas numpy scikit-learn matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Generate synthetic data (simulating customer churn data)\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'CustomerID': np.arange(1, 101),\n",
        "    'Tenure': np.random.randint(1, 72, 100),\n",
        "    'MonthlyCharges': np.random.uniform(20, 120, 100),\n",
        "    'TotalCharges': np.random.uniform(100, 8000, 100),\n",
        "    'Churn': np.random.choice([0, 1], 100)\n",
        "})\n",
        "\n",
        "# Data Cleaning and Preprocessing\n",
        "data['TotalCharges'] = data['TotalCharges'].replace(' ', np.nan)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split data into features and target variable\n",
        "X = data[['Tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "y = data['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Generate confusion matrix as an image\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix', fontsize=16)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(2)\n",
        "plt.xticks(tick_marks, ['No Churn', 'Churn'], rotation=45, fontsize=12)\n",
        "plt.yticks(tick_marks, ['No Churn', 'Churn'], fontsize=12)\n",
        "plt.ylabel('True label', fontsize=12)\n",
        "plt.xlabel('Predicted label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.close()\n",
        "\n",
        "# Generate ROC curve as an image\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc, color='darkorange', lw=2)\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC)', fontsize=16)\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curve.png')\n",
        "plt.close()\n",
        "\n",
        "# Create enhanced PDF report\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 14)\n",
        "        self.set_text_color(255, 165, 0)  # Orange color\n",
        "        self.cell(0, 10, 'Customer Churn Analysis Report', 0, 1, 'C')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.set_text_color(0, 102, 204)  # Blue color\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.set_text_color(0)\n",
        "        self.multi_cell(0, 10, body)\n",
        "        self.ln(5)\n",
        "\n",
        "# Initialize PDF\n",
        "pdf = PDF()\n",
        "\n",
        "# Title Page\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", 'B', 16)\n",
        "pdf.set_text_color(0, 102, 204)  # Blue color\n",
        "pdf.cell(200, 10, \"Data Science Project: Customer Churn Analysis\", ln=True, align='C')\n",
        "pdf.set_font(\"Arial\", 'I', 12)\n",
        "pdf.set_text_color(128)\n",
        "pdf.ln(10)\n",
        "pdf.cell(200, 10, \"A report analyzing customer churn patterns for a telecommunications company.\", ln=True, align='C')\n",
        "pdf.ln(20)\n",
        "\n",
        "# 1. Introduction\n",
        "pdf.chapter_title(\"1. Introduction\")\n",
        "pdf.chapter_body(\n",
        "    \"This project aims to predict customer churn for a telecommunications company. \"\n",
        "    \"The analysis seeks to identify key factors contributing to churn, understand customer behavior, \"\n",
        "    \"and provide actionable insights to improve customer retention. Machine learning techniques are \"\n",
        "    \"used to create a predictive model that informs retention strategies.\"\n",
        ")\n",
        "\n",
        "# 2. Methodology\n",
        "pdf.chapter_title(\"2. Methodology\")\n",
        "pdf.chapter_body(\n",
        "    \"The project follows a structured approach, beginning with data collection and preprocessing. \"\n",
        "    \"Data was cleaned by handling missing values, normalizing numerical features, and splitting the dataset \"\n",
        "    \"into training and test sets. A Random Forest model was chosen for its effectiveness in classification tasks. \"\n",
        "    \"Model performance was measured using accuracy, precision, recall, and ROC-AUC score.\"\n",
        ")\n",
        "\n",
        "# 3. Analysis and Results\n",
        "pdf.chapter_title(\"3. Analysis and Results\")\n",
        "pdf.chapter_body(\n",
        "    \"The Random Forest model achieved an accuracy of {:.2f}, indicating good predictive capability. \"\n",
        "    \"The confusion matrix and ROC curve provide visual representations of model performance. \"\n",
        "    \"The ROC-AUC score of {:.2f} suggests a strong ability to distinguish between customers who churn and those who do not.\".format(model.score(X_test, y_test), roc_auc)\n",
        ")\n",
        "\n",
        "pdf.image('confusion_matrix.png', x=50, w=100)\n",
        "pdf.ln(5)\n",
        "pdf.image('roc_curve.png', x=50, w=100)\n",
        "pdf.ln(5)\n",
        "\n",
        "pdf.chapter_title(\"Classification Report\")\n",
        "pdf.set_font(\"Courier\", '', 10)\n",
        "pdf.set_text_color(0)\n",
        "pdf.multi_cell(0, 5, report)\n",
        "pdf.ln(5)\n",
        "\n",
        "# 4. Conclusions and Recommendations\n",
        "pdf.chapter_title(\"4. Conclusions and Recommendations\")\n",
        "pdf.chapter_body(\n",
        "    \"The analysis indicates that longer tenure and higher monthly charges are significant factors contributing to churn. \"\n",
        "    \"To improve customer retention, the company should focus on enhancing customer service for long-term customers and \"\n",
        "    \"offer targeted discounts to customers with high monthly charges. Additionally, regular follow-ups and personalized offers \"\n",
        "    \"can further reduce churn rates.\"\n",
        ")\n",
        "\n",
        "# Save the PDF\n",
        "pdf_file = \"Customer_Churn_Analysis_Report_Enhanced.pdf\"\n",
        "pdf.output(pdf_file)\n",
        "\n",
        "print(f\"Enhanced PDF report generated successfully: {pdf_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5AH5rm7qdh-",
        "outputId": "d9423746-9a46-4f6c-b492-da19b2534a9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Enhanced PDF report generated successfully: Customer_Churn_Analysis_Report_Enhanced.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Compact only the necessary folder\n",
        "project_name = \"Complete_Data_Science_Project\"\n",
        "\n",
        "# Create a ZIP file of the project folder\n",
        "shutil.make_archive(project_name, 'zip', project_name)\n",
        "\n",
        "# Download the ZIP file\n",
        "files.download(f\"{project_name}.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zaOP3LW9q_HI",
        "outputId": "df04c140-4d68-4ece-bbf8-f7bd4e887b3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8d5cf6e-f5ae-4381-90cf-319b9990e7eb\", \"Complete_Data_Science_Project.zip\", 93182)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCHrxlu_tM8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}